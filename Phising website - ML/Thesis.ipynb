{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import random\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,KFold,StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,average_precision_score,recall_score,roc_auc_score\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,LabelEncoder,MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,BatchNormalization\n",
    "from keras.layers.core import Dense,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "Data=pd.read_csv(\"Phishing.csv\",header=\"infer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Data.iloc [:,1:-1]\n",
    "x=x.values\n",
    "y=Data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x1= preprocessing.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x1,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "clf_gini=DecisionTreeClassifier(criterion=\"gini\", random_state=100,max_depth=3, min_samples_leaf=5)\n",
    "clf_gini.fit(x_train, y_train)\n",
    "Y_pred=clf_gini.predict(x_test)\n",
    "from sklearn import metrics\n",
    "#metrics.accuracy_score(y_test,Y_pred)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "train_pred1=clf_gini.predict(x_train)\n",
    "test_pred1=clf_gini.predict(x_test)\n",
    "#print(train_pred1)\n",
    "#print(test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  90.63772048846675\n",
      "Sensitivity :  90.90167278661771\n",
      "Specificity :  90.30948756976154\n",
      "F1 score :  91.49897330595482\n",
      "Mattews correlation coefficient :  81.0909287924864\n",
      "Accuracy :  91.40660334690185\n",
      "Sensitivity :  92.11155378486056\n",
      "Specificity :  90.48117154811716\n",
      "F1 score :  92.40607513988809\n",
      "Mattews correlation coefficient :  82.51271212073331\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "train_pred1=clf_gini.predict(x_train)\n",
    "test_pred1=clf_gini.predict(x_test)\n",
    "\n",
    "confusion_matrix_train1 = []\n",
    "confusion_matrix_train1=confusion_matrix(y_train,train_pred1)\n",
    "TP1 = confusion_matrix_train1[1,1]\n",
    "TN1 = confusion_matrix_train1[0,0]\n",
    "FP1 = confusion_matrix_train1[0,1]\n",
    "FN1 = confusion_matrix_train1[1,0]\n",
    "\n",
    "Accuracy=((TP1+TN1)/float(TP1+TN1+FP1+FN1))  ##Accuracy\n",
    "Sensitivity=(TP1/float(TP1+FN1))             ##Sensitivity\n",
    "Specificity=(TN1/float(TN1+FP1))             ##Specificity\n",
    "F1=((2*TP1)/float((2*TP1)+FP1+FN1))     ## F1 score\n",
    "sqr1 = (TP1+FP1)*(TP1+FN1)*(TN1+FP1)*(TN1+FN1)\n",
    "MCC=(((TP1*TN1)-(FP1*FN1))/math.sqrt(sqr1)) ##Mattews correlation coefficient\n",
    "print(\"Accuracy : \",Accuracy*100)\n",
    "print(\"Sensitivity : \",Sensitivity*100)\n",
    "print(\"Specificity : \",Specificity*100)\n",
    "print(\"F1 score : \",F1*100)\n",
    "print(\"Mattews correlation coefficient : \",MCC*100)\n",
    "\n",
    "confusion_matrix_test1 = []\n",
    "confusion_matrix_test1=confusion_matrix(y_test,test_pred1)\n",
    "TP1 = confusion_matrix_test1[1,1]\n",
    "TN1 = confusion_matrix_test1[0,0]\n",
    "FP1 = confusion_matrix_test1[0,1]\n",
    "FN1 = confusion_matrix_test1[1,0]\n",
    "Accuracy=((TP1+TN1)/float(TP1+TN1+FP1+FN1))  ##Accuracy\n",
    "Sensitivity=(TP1/float(TP1+FN1))             ##Sensitivity\n",
    "Specificity=(TN1/float(TN1+FP1))             ##Specificity\n",
    "F1=((2*TP1)/float((2*TP1)+FP1+FN1))     ## F1 score\n",
    "sqr1 = (TP1+FP1)*(TP1+FN1)*(TN1+FP1)*(TN1+FN1)\n",
    "MCC=(((TP1*TN1)-(FP1*FN1))/math.sqrt(sqr1)) ##Mattews correlation coefficient\n",
    "print(\"Accuracy : \",Accuracy*100)\n",
    "print(\"Sensitivity : \",Sensitivity*100)\n",
    "print(\"Specificity : \",Specificity*100)\n",
    "print(\"F1 score : \",F1*100)\n",
    "print(\"Mattews correlation coefficient : \",MCC*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pydotplus\\nfrom sklearn.tree import export_graphviz\\nfrom IPython.display import Image\\ndot_data=tree.export_graphviz(clf_gini)\\ngraph=pydotplus.graph_from_dot_data(dot_data)\\nImage(graph.create_png())'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "dot_data=tree.export_graphviz(clf_gini)\n",
    "graph=pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.metrics import accuracy_score'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.metrics import accuracy_score'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maxdepths=[3,4,5,6,7,8,9,10,11,15,20,25,30,35,40,45,50,60]# alist contains\\ntrainAcc=np.zeros(len(maxdepths))\\ntestAcc=np.zeros(len(maxdepths))'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''maxdepths=[3,4,5,6,7,8,9,10,11,15,20,25,30,35,40,45,50,60]# alist contains\n",
    "trainAcc=np.zeros(len(maxdepths))\n",
    "testAcc=np.zeros(len(maxdepths))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'index=0\\nfor depth in maxdepths:\\n    clf=tree.DecisionTreeClassifier(max_depth=depth)\\n    clf=clf.fit(x_train,y_train)\\n    y_predTrain=clf.predict(x_train)\\n    y_predTest=clf.predict(x_test)\\n    trainAcc[index]=accuracy_score(y_train,y_predTrain)\\n    testAcc[index]=accuracy_score(y_test,y_predTest)\\n    index +=1'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''index=0\n",
    "for depth in maxdepths:\n",
    "    clf=tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    clf=clf.fit(x_train,y_train)\n",
    "    y_predTrain=clf.predict(x_train)\n",
    "    y_predTest=clf.predict(x_test)\n",
    "    trainAcc[index]=accuracy_score(y_train,y_predTrain)\n",
    "    testAcc[index]=accuracy_score(y_test,y_predTest)\n",
    "    index +=1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.plot(maxdepths,trainAcc,'ro-',maxdepths,testAcc,'bv--')\\nplt.legend(['Training Accuracy','Test Accuracy'])\\nplt.xlabel('Max Depth')\\nplt.ylabel('Accuracy')\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plt.plot(maxdepths,trainAcc,'ro-',maxdepths,testAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "having_IP_Address              0\n",
       "URL_Length                     0\n",
       "Shortining_Service             0\n",
       "having_At_Symbol               0\n",
       "double_slash_redirecting       0\n",
       "Prefix_Suffix                  0\n",
       "having_Sub_Domain              0\n",
       "SSLfinal_State                 0\n",
       "Domain_registeration_length    0\n",
       "Favicon                        0\n",
       "port                           0\n",
       "HTTPS_token                    0\n",
       "Request_URL                    0\n",
       "URL_of_Anchor                  0\n",
       "Links_in_tags                  0\n",
       "SFH                            0\n",
       "Submitting_to_email            0\n",
       "Abnormal_URL                   0\n",
       "Redirect                       0\n",
       "on_mouseover                   0\n",
       "RightClick                     0\n",
       "popUpWidnow                    0\n",
       "Iframe                         0\n",
       "age_of_domain                  0\n",
       "DNSRecord                      0\n",
       "web_traffic                    0\n",
       "Page_Rank                      0\n",
       "Google_Index                   0\n",
       "Links_pointing_to_page         0\n",
       "Statistical_report             0\n",
       "Result                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.isnull()\n",
    "Data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.40660334690185"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test,Y_pred)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "train_pred1=regressor.predict(x_train)\n",
    "test_pred1=regressor.predict(x_test)\n",
    "#print(train_pred1)\n",
    "train_pred1 = np.where(train_pred1 > 0.0, 1, -1)\n",
    "#print(train_pred1)\n",
    "#print(test_pred1)\n",
    "test_pred1 = np.where(test_pred1 > 0.0, 1, -1)\n",
    "#print(test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3521  421]\n",
      " [ 282 4620]]\n",
      "Accuracy :  92.05110809588422\n",
      "Sensitivity :  94.24724602203183\n",
      "Specificity :  89.32014205986809\n",
      "F1 score :  92.9296992859298\n",
      "Mattews correlation coefficient :  83.89967536564993\n",
      "[[ 844  112]\n",
      " [  62 1193]]\n",
      "Accuracy :  92.13025780189959\n",
      "Sensitivity :  95.0597609561753\n",
      "Specificity :  88.28451882845188\n",
      "F1 score :  93.203125\n",
      "Mattews correlation coefficient :  83.95706585407933\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "train_pred1=regressor.predict(x_train)\n",
    "test_pred1=regressor.predict(x_test)\n",
    "\n",
    "train_pred1 = np.where(train_pred1 > 0.0, 1, -1)\n",
    "\n",
    "confusion_matrix_train1 = []\n",
    "confusion_matrix_train1=confusion_matrix(y_train,train_pred1)\n",
    "print(confusion_matrix_train1)\n",
    "TP1 = confusion_matrix_train1[1,1]\n",
    "TN1 = confusion_matrix_train1[0,0]\n",
    "FP1 = confusion_matrix_train1[0,1]\n",
    "FN1 = confusion_matrix_train1[1,0]\n",
    "\n",
    "Accuracy=((TP1+TN1)/float(TP1+TN1+FP1+FN1))  ##Accuracy\n",
    "Sensitivity=(TP1/float(TP1+FN1))             ##Sensitivity\n",
    "Specificity=(TN1/float(TN1+FP1))             ##Specificity\n",
    "F1=((2*TP1)/float((2*TP1)+FP1+FN1))     ## F1 score\n",
    "sqr1 = (TP1+FP1)*(TP1+FN1)*(TN1+FP1)*(TN1+FN1)\n",
    "MCC=(((TP1*TN1)-(FP1*FN1))/math.sqrt(sqr1)) ##Mattews correlation coefficient\n",
    "print(\"Accuracy : \",Accuracy*100)\n",
    "print(\"Sensitivity : \",Sensitivity*100)\n",
    "print(\"Specificity : \",Specificity*100)\n",
    "print(\"F1 score : \",F1*100)\n",
    "print(\"Mattews correlation coefficient : \",MCC*100)\n",
    "\n",
    "\n",
    "test_pred1 = np.where(test_pred1 > 0.0, 1, -1)\n",
    "\n",
    "confusion_matrix_test1 = []\n",
    "confusion_matrix_test1=confusion_matrix(y_test,test_pred1)\n",
    "print(confusion_matrix_test1)\n",
    "TP1 = confusion_matrix_test1[1,1]\n",
    "TN1 = confusion_matrix_test1[0,0]\n",
    "FP1 = confusion_matrix_test1[0,1]\n",
    "FN1 = confusion_matrix_test1[1,0]\n",
    "Accuracy=((TP1+TN1)/float(TP1+TN1+FP1+FN1))  ##Accuracy\n",
    "Sensitivity=(TP1/float(TP1+FN1))             ##Sensitivity\n",
    "Specificity=(TN1/float(TN1+FP1))             ##Specificity\n",
    "F1=((2*TP1)/float((2*TP1)+FP1+FN1))     ## F1 score\n",
    "sqr1 = (TP1+FP1)*(TP1+FN1)*(TN1+FP1)*(TN1+FN1)\n",
    "MCC=(((TP1*TN1)-(FP1*FN1))/math.sqrt(sqr1)) ##Mattews correlation coefficient\n",
    "print(\"Accuracy : \",Accuracy*100)\n",
    "print(\"Sensitivity : \",Sensitivity*100)\n",
    "print(\"Specificity : \",Specificity*100)\n",
    "print(\"F1 score : \",F1*100)\n",
    "print(\"Mattews correlation coefficient : \",MCC*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data = pd.DataFrame({'Actual':y_test.flatten(),'Predicted':y_pred.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf1 = Data.head(40)\\ndf1.plot(kind='bar',figsize=(16,10))\\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df1 = Data.head(40)\n",
    "df1.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn import metrics\\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import random\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=None\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "numNeighbours=[1,5,10,15,20,25,30]\n",
    "trainAcc=[]\n",
    "testAcc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(train_tp)\\nprint(train_tn)\\nprint(train_fp)\\nprint(trian_fn)\\nprint(test_tp)\\nprint(test_tn)\\nprint(test_fp)\\nprint(test_fn)\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tp = []\n",
    "train_tn = []\n",
    "train_fp = []\n",
    "trian_fn = []\n",
    "\n",
    "\n",
    "test_tp = []\n",
    "test_tn = []\n",
    "test_fp = []\n",
    "test_fn = []\n",
    "\n",
    "\n",
    "\n",
    "for k in numNeighbours:\n",
    "    clf=KNeighborsClassifier(n_neighbors=k, metric='minkowski',p=2)\n",
    "    clf.fit(x_train,y_train)\n",
    "    \n",
    "    y_predTrain=clf.predict(x_train)\n",
    "    confusion_matrix_train1 = []\n",
    "    confusion_matrix_train1=confusion_matrix(y_train,y_predTrain)\n",
    "    #print(confusion_matrix_train1)\n",
    "    train_tp.append(confusion_matrix_train1[1,1])\n",
    "    train_tn.append(confusion_matrix_train1[0,0])\n",
    "    train_fp.append(confusion_matrix_train1[0,1])\n",
    "    trian_fn.append(confusion_matrix_train1[1,0])\n",
    "    #Accuracy=((train_tp+train_tn)/float(train_tp+train_tn+train_fp+trian_fn))  ##Accuracy\n",
    "    #print(\"Accuracy : \",Accuracy*100)\n",
    "    \n",
    "    y_predTest=clf.predict(x_test)\n",
    "    confusion_matrix_test1 = []\n",
    "    confusion_matrix_test1=confusion_matrix(y_test,y_predTest)\n",
    "    #print(confusion_matrix_test1)\n",
    "    test_tp.append(confusion_matrix_test1[1,1])\n",
    "    test_tn.append(confusion_matrix_test1[0,0])\n",
    "    test_fp.append(confusion_matrix_test1[0,1])\n",
    "    test_fn.append(confusion_matrix_test1[1,0])\n",
    "    \n",
    "    trainAcc.append(accuracy_score(y_train,y_predTrain))\n",
    "    testAcc.append(accuracy_score(y_test,y_predTest))\n",
    "    \n",
    "'''\n",
    "print(train_tp)\n",
    "print(train_tn)\n",
    "print(train_fp)\n",
    "print(trian_fn)\n",
    "print(test_tp)\n",
    "print(test_tn)\n",
    "print(test_fp)\n",
    "print(test_fn)\n",
    "'''    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  94.93327301515494\n",
      "Sensitivity :  95.91920016323199\n",
      "Specificity :  93.70718091854859\n",
      "F1 score :  95.4517766497462\n",
      "Mattews correlation coefficient :  89.73885022114868\n",
      "Accuracy :  93.43891402714932\n",
      "Sensitivity :  95.0597609561753\n",
      "Specificity :  91.30890052356021\n",
      "F1 score :  94.27103911497431\n",
      "Mattews correlation coefficient :  86.61257740227852\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "TP1 = mean(train_tp)\n",
    "TN1 = mean(train_tn)\n",
    "FP1 = mean(train_fp)\n",
    "FN1 = mean(trian_fn)\n",
    "\n",
    "Accuracy=((TP1+TN1)/float(TP1+TN1+FP1+FN1))  ##Accuracy\n",
    "Sensitivity=(TP1/float(TP1+FN1))             ##Sensitivity\n",
    "Specificity=(TN1/float(TN1+FP1))             ##Specificity\n",
    "F1=((2*TP1)/float((2*TP1)+FP1+FN1))     ## F1 score\n",
    "sqr1 = (TP1+FP1)*(TP1+FN1)*(TN1+FP1)*(TN1+FN1)\n",
    "MCC=(((TP1*TN1)-(FP1*FN1))/math.sqrt(sqr1)) ##Mattews correlation coefficient\n",
    "print(\"Accuracy : \",Accuracy*100)\n",
    "print(\"Sensitivity : \",Sensitivity*100)\n",
    "print(\"Specificity : \",Specificity*100)\n",
    "print(\"F1 score : \",F1*100)\n",
    "print(\"Mattews correlation coefficient : \",MCC*100)\n",
    "\n",
    "\n",
    "TP1 = mean(test_tp)\n",
    "TN1 = mean(test_tn)\n",
    "FP1 = mean(test_fp)\n",
    "FN1 = mean(test_fn)\n",
    "\n",
    "Accuracy=((TP1+TN1)/float(TP1+TN1+FP1+FN1))  ##Accuracy\n",
    "Sensitivity=(TP1/float(TP1+FN1))             ##Sensitivity\n",
    "Specificity=(TN1/float(TN1+FP1))             ##Specificity\n",
    "F1=((2*TP1)/float((2*TP1)+FP1+FN1))     ## F1 score\n",
    "sqr1 = (TP1+FP1)*(TP1+FN1)*(TN1+FP1)*(TN1+FN1)\n",
    "MCC=(((TP1*TN1)-(FP1*FN1))/math.sqrt(sqr1)) ##Mattews correlation coefficient\n",
    "print(\"Accuracy : \",Accuracy*100)\n",
    "print(\"Sensitivity : \",Sensitivity*100)\n",
    "print(\"Specificity : \",Specificity*100)\n",
    "print(\"F1 score : \",F1*100)\n",
    "print(\"Mattews correlation coefficient : \",MCC*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3869   73]\n",
      " [  38 4864]]\n",
      "Accuracy :  98.7449118046133\n",
      "Sensitivity :  99.2248062015504\n",
      "Specificity :  98.14814814814815\n",
      "F1 score :  98.87183656875699\n",
      "Mattews correlation coefficient :  97.46081553273393\n",
      "[[ 902   54]\n",
      " [  31 1224]]\n",
      "Accuracy :  96.15558570782451\n",
      "Sensitivity :  97.52988047808765\n",
      "Specificity :  94.35146443514645\n",
      "F1 score :  96.64429530201343\n",
      "Mattews correlation coefficient :  92.16624708352609\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 10)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_predTrain = classifier.predict(x_train)\n",
    "\n",
    "confusion_matrix_train1 = []\n",
    "confusion_matrix_train1=confusion_matrix(y_train,y_predTrain)\n",
    "\n",
    "print(confusion_matrix_train1)\n",
    "TP1 = confusion_matrix_train1[1,1]\n",
    "TN1 = confusion_matrix_train1[0,0]\n",
    "FP1 = confusion_matrix_train1[0,1]\n",
    "FN1 = confusion_matrix_train1[1,0]\n",
    "\n",
    "Accuracy=((TP1+TN1)/float(TP1+TN1+FP1+FN1))  ##Accuracy\n",
    "Sensitivity=(TP1/float(TP1+FN1))             ##Sensitivity\n",
    "Specificity=(TN1/float(TN1+FP1))             ##Specificity\n",
    "F1=((2*TP1)/float((2*TP1)+FP1+FN1))     ## F1 score\n",
    "sqr1 = (TP1+FP1)*(TP1+FN1)*(TN1+FP1)*(TN1+FN1)\n",
    "MCC=(((TP1*TN1)-(FP1*FN1))/math.sqrt(sqr1)) ##Mattews correlation coefficient\n",
    "print(\"Accuracy : \",Accuracy*100)\n",
    "print(\"Sensitivity : \",Sensitivity*100)\n",
    "print(\"Specificity : \",Specificity*100)\n",
    "print(\"F1 score : \",F1*100)\n",
    "print(\"Mattews correlation coefficient : \",MCC*100)\n",
    "\n",
    "\n",
    "y_predTest=classifier.predict(x_test)\n",
    "\n",
    "confusion_matrix_test1 = []\n",
    "confusion_matrix_test1=confusion_matrix(y_test,y_predTest)\n",
    "\n",
    "print(confusion_matrix_test1)\n",
    "TP1 = confusion_matrix_test1[1,1]\n",
    "TN1 = confusion_matrix_test1[0,0]\n",
    "FP1 = confusion_matrix_test1[0,1]\n",
    "FN1 = confusion_matrix_test1[1,0]\n",
    "\n",
    "Accuracy=((TP1+TN1)/float(TP1+TN1+FP1+FN1))  ##Accuracy\n",
    "Sensitivity=(TP1/float(TP1+FN1))             ##Sensitivity\n",
    "Specificity=(TN1/float(TN1+FP1))             ##Specificity\n",
    "F1=((2*TP1)/float((2*TP1)+FP1+FN1))     ## F1 score\n",
    "sqr1 = (TP1+FP1)*(TP1+FN1)*(TN1+FP1)*(TN1+FN1)\n",
    "MCC=(((TP1*TN1)-(FP1*FN1))/math.sqrt(sqr1)) ##Mattews correlation coefficient\n",
    "print(\"Accuracy : \",Accuracy*100)\n",
    "print(\"Sensitivity : \",Sensitivity*100)\n",
    "print(\"Specificity : \",Specificity*100)\n",
    "print(\"F1 score : \",F1*100)\n",
    "print(\"Mattews correlation coefficient : \",MCC*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3523  419]\n",
      " [ 255 4647]]\n",
      "Accuracy :  92.37901402080506\n",
      "Sensitivity :  94.79804161566707\n",
      "Specificity :  89.37087772704211\n",
      "F1 score :  93.23836276083468\n",
      "Mattews correlation coefficient :  84.57327435598869\n",
      "[[ 855  101]\n",
      " [  56 1199]]\n",
      "Accuracy :  92.8991406603347\n",
      "Sensitivity :  95.5378486055777\n",
      "Specificity :  89.43514644351464\n",
      "F1 score :  93.85518590998043\n",
      "Mattews correlation coefficient :  85.52653363066133\n"
     ]
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'rbf', probability=True, random_state=0, gamma=0.1, C=1.0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_predTrain = classifier.predict(x_train)\n",
    "\n",
    "confusion_matrix_train1 = []\n",
    "confusion_matrix_train1=confusion_matrix(y_train,y_predTrain)\n",
    "\n",
    "print(confusion_matrix_train1)\n",
    "TP1 = confusion_matrix_train1[1,1]\n",
    "TN1 = confusion_matrix_train1[0,0]\n",
    "FP1 = confusion_matrix_train1[0,1]\n",
    "FN1 = confusion_matrix_train1[1,0]\n",
    "\n",
    "Accuracy=((TP1+TN1)/float(TP1+TN1+FP1+FN1))  ##Accuracy\n",
    "Sensitivity=(TP1/float(TP1+FN1))             ##Sensitivity\n",
    "Specificity=(TN1/float(TN1+FP1))             ##Specificity\n",
    "F1=((2*TP1)/float((2*TP1)+FP1+FN1))     ## F1 score\n",
    "sqr1 = (TP1+FP1)*(TP1+FN1)*(TN1+FP1)*(TN1+FN1)\n",
    "MCC=(((TP1*TN1)-(FP1*FN1))/math.sqrt(sqr1)) ##Mattews correlation coefficient\n",
    "print(\"Accuracy : \",Accuracy*100)\n",
    "print(\"Sensitivity : \",Sensitivity*100)\n",
    "print(\"Specificity : \",Specificity*100)\n",
    "print(\"F1 score : \",F1*100)\n",
    "print(\"Mattews correlation coefficient : \",MCC*100)\n",
    "\n",
    "\n",
    "y_predTest=classifier.predict(x_test)\n",
    "\n",
    "confusion_matrix_test1 = []\n",
    "confusion_matrix_test1=confusion_matrix(y_test,y_predTest)\n",
    "\n",
    "print(confusion_matrix_test1)\n",
    "TP1 = confusion_matrix_test1[1,1]\n",
    "TN1 = confusion_matrix_test1[0,0]\n",
    "FP1 = confusion_matrix_test1[0,1]\n",
    "FN1 = confusion_matrix_test1[1,0]\n",
    "\n",
    "Accuracy=((TP1+TN1)/float(TP1+TN1+FP1+FN1))  ##Accuracy\n",
    "Sensitivity=(TP1/float(TP1+FN1))             ##Sensitivity\n",
    "Specificity=(TN1/float(TN1+FP1))             ##Specificity\n",
    "F1=((2*TP1)/float((2*TP1)+FP1+FN1))     ## F1 score\n",
    "sqr1 = (TP1+FP1)*(TP1+FN1)*(TN1+FP1)*(TN1+FN1)\n",
    "MCC=(((TP1*TN1)-(FP1*FN1))/math.sqrt(sqr1)) ##Mattews correlation coefficient\n",
    "print(\"Accuracy : \",Accuracy*100)\n",
    "print(\"Sensitivity : \",Sensitivity*100)\n",
    "print(\"Specificity : \",Specificity*100)\n",
    "print(\"F1 score : \",F1*100)\n",
    "print(\"Mattews correlation coefficient : \",MCC*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
